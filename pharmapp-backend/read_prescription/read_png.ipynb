{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaryas127/Documents/GitHub/pharmapp/.conda/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/aaryas127/Documents/GitHub/pharmapp/.conda/lib/python3.12/site-packages/transformers/models/bart/configuration_bart.py:176: UserWarning: Please make sure the config includes `forced_bos_token_id=0` in future versions. The config can simply be saved and uploaded again to be fixed.\n",
      "  warnings.warn(\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizerFast'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading model or tokenizer: \n",
      "RagRetriever requires the faiss library but it was not found in your environment. Checkout the instructions on the\n",
      "installation page of its repo: https://github.com/facebookresearch/faiss/blob/master/INSTALL.md and follow the ones\n",
      "that match your environment. Please note that you may need to restart your runtime after installation.\n",
      "\n",
      "No text detected in the image.\n",
      "Extracted Text: \n",
      "Error during model inference: name 'model' is not defined\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import pytesseract\n",
    "import torch\n",
    "from transformers import RagTokenizer, RagRetriever, RagSequenceForGeneration\n",
    "\n",
    "# Initialize the RAG components\n",
    "try:\n",
    "    tokenizer = RagTokenizer.from_pretrained(\"facebook/rag-token-nq\")\n",
    "    retriever = RagRetriever.from_pretrained(\"facebook/rag-token-nq\", index_name=\"exact\")\n",
    "    model = RagSequenceForGeneration.from_pretrained(\"facebook/rag-token-nq\", retriever=retriever)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model or tokenizer: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Load and process the PNG image\n",
    "image_path = \"/Users/aaryas127/Documents/GitHub/pharmapp/pharmapp-backend/uploads/unnamed-2.png\"\n",
    "try:\n",
    "    image = Image.open(image_path)\n",
    "except FileNotFoundError:\n",
    "    print(\"The specified image file was not found.\")\n",
    "    exit()\n",
    "\n",
    "# Extract text from the image using OCR\n",
    "text = pytesseract.image_to_string(image)\n",
    "if not text.strip():\n",
    "    print(\"No text detected in the image.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Extracted Text: {text}\")\n",
    "\n",
    "# Tokenize the text and prepare it for RAG\n",
    "try:\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    generated_ids = model.generate(**inputs)\n",
    "    output = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "    print(\"Generated Output:\", output)\n",
    "except Exception as e:\n",
    "    print(f\"Error during model inference: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package            Version\n",
      "------------------ -----------\n",
      "appnope            0.1.4\n",
      "asttokens          2.4.1\n",
      "comm               0.2.2\n",
      "debugpy            1.8.7\n",
      "decorator          5.1.1\n",
      "exceptiongroup     1.2.2\n",
      "executing          2.1.0\n",
      "importlib_metadata 8.5.0\n",
      "ipykernel          6.29.5\n",
      "ipython            8.18.1\n",
      "jedi               0.19.1\n",
      "jupyter_client     8.6.3\n",
      "jupyter_core       5.7.2\n",
      "matplotlib-inline  0.1.7\n",
      "nest-asyncio       1.6.0\n",
      "packaging          24.1\n",
      "parso              0.8.4\n",
      "pexpect            4.9.0\n",
      "pip                24.3.1\n",
      "platformdirs       4.3.6\n",
      "prompt_toolkit     3.0.48\n",
      "psutil             6.1.0\n",
      "ptyprocess         0.7.0\n",
      "pure_eval          0.2.3\n",
      "Pygments           2.18.0\n",
      "python-dateutil    2.9.0.post0\n",
      "pyzmq              26.2.0\n",
      "setuptools         56.0.0\n",
      "six                1.16.0\n",
      "stack-data         0.6.3\n",
      "tornado            6.4.1\n",
      "traitlets          5.14.3\n",
      "typing_extensions  4.12.2\n",
      "wcwidth            0.2.13\n",
      "zipp               3.20.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
