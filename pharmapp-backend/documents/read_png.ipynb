{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import pytesseract\n",
    "\n",
    "# Open the image and apply EXIF orientation if necessary\n",
    "image = Image.open(\"/Users/aaryas127/Documents/GitHub/pharmapp/pharmapp-backend/uploads/IMG_8512.jpeg\")\n",
    "image = ImageOps.exif_transpose(image)\n",
    "\n",
    "# Extract all text from the image\n",
    "full_text = pytesseract.image_to_string(image)\n",
    "\n",
    "# Find the position of \"Dr.\" in the text\n",
    "start_index = full_text.find(\"Dr.\")\n",
    "\n",
    "# Check if \"Dr.\" was found, and if so, extract text from that position onward\n",
    "if start_index != -1:\n",
    "    text = full_text[start_index:]\n",
    "    print(\"Extracted Text Starting from 'Dr.':\\n\", text)\n",
    "else:\n",
    "    print(\"The keyword 'Dr.' was not found in the image.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flan_pipeline = pipeline(\"text2text-generation\", model=\"google/flan-t5-large\", device=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the Flan-T5 model with GPU support if available, or use CPU\n",
    "flan_pipeline = pipeline(\"text2text-generation\", model=\"google/flan-t5-large\", device=-1)\n",
    "\n",
    "# Updated prompt with added structure guidance and example format\n",
    "text_input = f\"\"\"\n",
    "Please extract and organize the information from the following medical text into a structured format with specific sections. Use bullet points and organize under the following headers:\n",
    "\n",
    "1. **Doctor's Information**\n",
    "   - Name:\n",
    "   - Clinic:\n",
    "   - Address:\n",
    "   - Practitioner Number:\n",
    "   - Contact Info (Phone and Fax):\n",
    "\n",
    "2. **Patient Details**\n",
    "   - Name:\n",
    "   - Date of Birth (DOB):\n",
    "   - Address:\n",
    "   - Contact Number:\n",
    "   - Health Insurance Number:\n",
    "\n",
    "3. **Prescription**\n",
    "   - Medication:\n",
    "   - Dosage Instructions:\n",
    "   - Quantity:\n",
    "   - Repeats:\n",
    "\n",
    "4. **Document Metadata**\n",
    "   - Written Date:\n",
    "   - Created By:\n",
    "\n",
    "Medical Text:\n",
    "\\\"\\\"\\\"{text}\\\"\\\"\\\"\n",
    "\n",
    "Return the output with this structure, clearly formatted and organized.\n",
    "\"\"\"\n",
    "\n",
    "# Generate the structured response\n",
    "response = flan_pipeline([text_input], max_length=512, do_sample=False)\n",
    "\n",
    "# Print the structured output\n",
    "print(\"Structured Output:\\n\", response[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(\n",
    "  base_url=\"https://integrate.api.nvidia.com/v1\",  # You can change this to OpenAI's URL if needed\n",
    "  api_key=\"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\"\n",
    ")\n",
    "\n",
    "# Define the prompt, with the variable 'text' inserted\n",
    "prompt = f\"\"\"\n",
    "Please extract the following details from the medical text and format them into distinct sections:\n",
    "\n",
    "**Doctor's Information**\n",
    "- Name\n",
    "- Clinic\n",
    "- Address\n",
    "- Practitioner Number\n",
    "- Contact Info\n",
    "\n",
    "**Patient Details**\n",
    "- Name\n",
    "- DOB\n",
    "- Address\n",
    "- Contact Info\n",
    "- Health Insurance Number\n",
    "\n",
    "**Prescription**\n",
    "- Medication\n",
    "- Dosage Instructions\n",
    "- Quantity\n",
    "- Repeats\n",
    "\n",
    "Medical Text:\n",
    "\\\"\\\"\\\"{text}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "# Request completion from OpenAI's model\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"meta/llama-3.2-3b-instruct\",  # You can switch this model to one compatible with OpenAI if needed\n",
    "  messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "  temperature=0.2,\n",
    "  top_p=0.7,\n",
    "  max_tokens=1024,\n",
    "  stream=True\n",
    ")\n",
    "\n",
    "# Collect and print the response as it's streamed\n",
    "for chunk in completion:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Set up Nvidia API endpoint and authorization\n",
    "api_url = \"https://integrate.api.nvidia.com/v1/completions\"\n",
    "headers = {\n",
    "    \"Authorization\": \"Bearer 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\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# Define the structured prompt to guide the model\n",
    "medical_text = \"\"\"\n",
    "Dr. Germin Attia MD CCFP Terry Fox Medical\n",
    "5380 Terry Fox Way #10\n",
    "Mississauga Ontario L5V OAS\n",
    "Pract. No.:137560\n",
    "Tel: 905-858-3030\n",
    "Fax: 905-858-3031\n",
    "\n",
    "Written Date: November 5, 2024\n",
    "AARYA G SHAH DOB:Jan 27, 2003\n",
    "44 BRETON AVE\n",
    "MISSISSAUGA, ON L4Z4K2\n",
    "905-281-2404\n",
    "Health Ins.#123456789\n",
    "\n",
    "VENTOLIN HFA 100@G\n",
    "1-2 puffs Q6 Hrs PRN\n",
    "Qty:1 Repeats:0\n",
    "\"\"\"\n",
    "\n",
    "# Structured prompt\n",
    "prompt = f\"\"\"\n",
    "Please extract the following details from the medical text and format them into structured sections:\n",
    "\n",
    "**Doctor's Information**\n",
    "- Name\n",
    "- Clinic\n",
    "- Address\n",
    "- Practitioner Number\n",
    "- Contact Info\n",
    "\n",
    "**Patient Details**\n",
    "- Name\n",
    "- DOB\n",
    "- Address\n",
    "- Contact Info\n",
    "- Health Insurance Number\n",
    "\n",
    "**Prescription**\n",
    "- Medication\n",
    "- Dosage Instructions\n",
    "- Quantity\n",
    "- Repeats\n",
    "\n",
    "Medical Text:\n",
    "\\\"\\\"\\\"{medical_text}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "# Define the payload for the completion request\n",
    "payload = {\n",
    "    \"model\": \"meta/llama-3.2-3b-instruct\",\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "    \"temperature\": 0.2,\n",
    "    \"top_p\": 0.7,\n",
    "    \"max_tokens\": 1024,\n",
    "    \"stream\": True\n",
    "}\n",
    "\n",
    "# Make the POST request to Nvidia's API\n",
    "response = requests.post(api_url, headers=headers, json=payload, stream=True)\n",
    "\n",
    "# Parse and print structured response\n",
    "structured_output = \"\"\n",
    "for line in response.iter_lines():\n",
    "    if line:\n",
    "        try:\n",
    "            # Attempt to parse each line as JSON\n",
    "            chunk = json.loads(line.decode('utf-8'))\n",
    "            if \"choices\" in chunk and chunk[\"choices\"][0][\"delta\"][\"content\"] is not None:\n",
    "                structured_output += chunk[\"choices\"][0][\"delta\"][\"content\"]\n",
    "        except json.JSONDecodeError:\n",
    "            # Skip lines that cannot be parsed as JSON\n",
    "            continue\n",
    "\n",
    "print(\"Structured Output:\\n\", structured_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
