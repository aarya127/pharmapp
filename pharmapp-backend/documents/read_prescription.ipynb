{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import pytesseract\n",
    "\n",
    "# Open the image and apply EXIF orientation if necessary\n",
    "image = Image.open(\"/Users/aaryas127/Documents/GitHub/pharmapp/pharmapp-backend/uploads/IMG_8512.jpeg\")\n",
    "image = ImageOps.exif_transpose(image)\n",
    "\n",
    "# Extract all text from the image\n",
    "full_text = pytesseract.image_to_string(image)\n",
    "\n",
    "# Find the position of \"Dr.\" in the text\n",
    "start_index = full_text.find(\"Dr.\")\n",
    "\n",
    "# Check if \"Dr.\" was found, and if so, extract text from that position onward\n",
    "if start_index != -1:\n",
    "    text = full_text[start_index:]\n",
    "    print(\"Extracted Text Starting from 'Dr.':\\n\", text)\n",
    "else:\n",
    "    print(\"The keyword 'Dr.' was not found in the image.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the entire file content\n",
    "with open(\"/Users/aaryas127/Documents/GitHub/pharmapp/pharmapp-backend/api_key.txt\", 'r') as file:\n",
    "    content = file.read()\n",
    "    print(content)\n",
    "\n",
    "# Reading the file line by line\n",
    "with open(\"/Users/aaryas127/Documents/GitHub/pharmapp/pharmapp-backend/api_key.txt\", 'r') as file:\n",
    "    for line in file:\n",
    "        print(line.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = OpenAI(\n",
    "  base_url=\"https://integrate.api.nvidia.com/v1\",  # You can change this to OpenAI's URL if needed\n",
    "  api_key=str(content)\n",
    ")\n",
    "\n",
    "# Define the prompt, with the variable 'text' inserted\n",
    "prompt = f\"\"\"\n",
    "Please extract the following details from the medical text and format them into distinct sections:\n",
    "\n",
    "**Doctor's Information**\n",
    "- Name\n",
    "- Clinic\n",
    "- Address\n",
    "- Practitioner Number\n",
    "- Contact Info\n",
    "\n",
    "**Patient Details**\n",
    "- Name\n",
    "- DOB\n",
    "- Address\n",
    "- Contact Info\n",
    "- Health Insurance Number\n",
    "\n",
    "**Prescription**\n",
    "- Medication\n",
    "- Dosage Instructions\n",
    "- Quantity\n",
    "- Repeats\n",
    "\n",
    "Medical Text:\n",
    "\\\"\\\"\\\"{text}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "# Request completion from OpenAI's model\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"meta/llama-3.2-3b-instruct\",  # You can switch this model to one compatible with OpenAI if needed\n",
    "  messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "  temperature=0.2,\n",
    "  top_p=0.7,\n",
    "  max_tokens=1024,\n",
    "  stream=True\n",
    ")\n",
    "\n",
    "# Collect and print the response as it's streamed\n",
    "for chunk in completion:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        output = chunk.choices[0].delta.content\n",
    "        print(output, end=\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
